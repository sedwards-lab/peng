# Concurrency

I'm concerned that the strict pyramid structure of our current fork tree might
not compose well. At present, SSM seems well-suited to constructing static
data flow pipelines: I can imagine useful little libraries for producer,
consumer, and processor components in such pipelines. The caller can declare
a fixed number of variables to use as "pipes" between these components, and
fork them all off at once to do their thing (and these components can
themselves fork off internal components, whose functionality they
encapsulate):


    -- parent process P

    -- declare a variable to use as pipe
    var v = ___

    -- spawn a pipeline between processes A, B, and C
    fork A(&v), B(&v), C(&v)

    -- fork tree:
    --
    --      P----+----+
    --      |    |    |
    --      v    v    v             (1)
    --      A -> B -> C
    --
    -- (roots of the fork tree)

In that diagram, the process P starts by forking out the A-B-C pipeline. The
problem I want to solve is, how can we get the process P to later spawn the
following fork tree, where the A-B-C runs concurrently alongside the D-E
pipeline:

    -- How can we dynamically create an additional pipeline:
    --
    --      P----+----+----+----+
    --      |    |    |    |    |
    --      v    v    v    v    v   (2)
    --      A -> B -> C    D -> E

However, this is predicated on the caller knowing the topology of the pipeline
before forking. Since the fork statement is blocking, the caller is unable to
do anything once it has handed off control. For instance, it cannot wait
around and decide to spawn a new pipeline until fork statement returns;
I imagine this will be useful in the IoT/Bluetooth context, where we might
want to spawn new pipelines in response to new devices joining the mesh
network.

Within the current model, I can think of three workarounds. The first is to
just construct all possible pipelines ahead of time, and have all component
processes lie dormant until they are needed to process data. In the diagrams
above, this would look like parent process P just forking out the D-E pipeline
alongside A-B-C. So, skipping diagram (1), and just starting with (2) from the
get-go. But that's not a dynamic solution.

The second workaround is to somehow signal A-B-C to return control to P, so
that it can then restart A-B-C alongside D-E. But expecting components to
always be hardwired with some mechanism to restart them seems like it would be
tedious for the programmer.

The third workaround is to spawn a process P' alongside A-B-C, which can be in
charge of later spawning D-E without having to restart A-B-C:


    --      P----+----+----+
    --      |    |    |    |
    --      v    v    v    v        (3)
    --      A -> B -> C    P'
    --
    --      some time later ...
    --
    --      P----+----+----+
    --      |    |    |    |
    --      v    v    v    v        (4)
    --      A -> B -> C    P'---+---+
    --                     |    |   |
    --                     v    v   v
    --                     D -> E   P''

This pattern could allow us to support non-blocking forks, by pushing the
statements following the first fork in P into P', which in turn pushes the
statements following the second fork into P''. In other words, P' represents
the *continuation* of P. And this kind of code is tedious to write out by
hand, but can easily be generated by a compiler.
